#!/usr/bin/env node

/**
 * Direct Upload to BigQuery
 */

import { getBigQueryService } from '../src/lib/bigquery-service'
import { config } from 'dotenv'
import fs from 'fs'

// Load environment variables
config({ path: '.env.local' })

async function main() {
  console.log('ğŸ“¤ Direct Upload to BigQuery')
  console.log('===========================\n')

  const dataPath = '/tmp/simple-bigquery-data.ndjson'

  try {
    console.log('1ï¸âƒ£  Checking data file...')
    const stats = fs.statSync(dataPath)
    console.log(`   ğŸ“„ File size: ${(stats.size / 1024 / 1024).toFixed(2)} MB`)

    console.log('2ï¸âƒ£  Starting BigQuery upload...')
    const bigQueryService = getBigQueryService()
    const job = await bigQueryService.loadSearchTermsData(dataPath)

    console.log('\nğŸ‰ Upload complete!')
    console.log(`   ğŸ’¾ Table: commercecrafted.amazon_analytics.search_terms`)
    console.log(`   ğŸ—“ï¸  Period: 2025-06-29 to 2025-07-05`)
    console.log(`   ğŸŒ Marketplace: ATVPDKIKX0DER (US Amazon)`)

    console.log('\nğŸš€ Your BigQuery data is ready!')

  } catch (error) {
    console.error('\nâŒ Upload failed:', error)
    process.exit(1)
  }
}

main().catch(console.error)